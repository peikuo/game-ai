#!/usr/bin/env python
"""
Test script to verify TTS functionality in the Game AI.
This script initializes the TTS components directly to verify proper configuration.
"""

import soundfile as sf
import numpy as np
import os
import argparse
import logging
import sys
from pathlib import Path

from src.tts.tts_manager import TTSManager
from src.utils.config_loader import load_config

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger("tts_test")


def test_tts_initialization():
    """Test TTS initialization with different config structures."""
    # Load the default config
    config = load_config("config/default.yaml")

    # Ensure audio config exists and is enabled
    if "audio" not in config:
        config["audio"] = {}
    config["audio"]["enabled"] = True

    logger.info(f"Testing TTS with full config: {config.get('audio', {})}")

    # Test 1: Initialize with full config
    try:
        tts_manager1 = TTSManager(config)
        logger.info("✅ TTS initialized successfully with full config")
        logger.info(
            f"Voice: {tts_manager1.voice_id}, Model: {tts_manager1.repo_id}")
    except Exception as e:
        logger.error(f"❌ Failed to initialize TTS with full config: {e}")

    # Test 2: Initialize with just audio section
    try:
        audio_config = config.get("audio", {})
        tts_manager2 = TTSManager(audio_config)
        logger.info("✅ TTS initialized successfully with audio config section")
        logger.info(
            f"Voice: {tts_manager2.voice_id}, Model: {tts_manager2.repo_id}")
    except Exception as e:
        logger.error(
            f"❌ Failed to initialize TTS with audio config section: {e}")

    # Test 3: Test TTS with a sample text
    try:
        test_text = "This is a test of the text to speech system."
        logger.info(f"Testing TTS speech generation with text: '{test_text}'")

        # Create temp directory if it doesn't exist
        temp_dir = Path("temp_audio")
        temp_dir.mkdir(exist_ok=True)

        # Generate and play speech directly
        success = tts_manager2.speak_monologue(test_text)
        if success:
            logger.info("✅ TTS generated and played speech successfully")
        else:
            logger.warning("⚠️ TTS failed to generate or play speech")
    except Exception as e:
        logger.error(f"❌ Failed to generate or play speech: {e}")


def synthesize_to_wav(tts_manager, text, out_path, voice_id=None):
    """Synthesize text to WAV file using TTSManager"""
    if not text:
        print("No text provided")
        return False

    if not tts_manager.is_available():
        print("TTS functionality is not available")
        return False

    try:
        # Create directory if it doesn't exist
        os.makedirs(os.path.dirname(out_path), exist_ok=True)

        # Use specified voice or default
        voice = voice_id or tts_manager.voice_id

        # Preprocess text to handle newlines and other special characters
        processed_text = tts_manager._preprocess_text(text)

        # Process the text using the pipeline
        for result in tts_manager.zh_pipeline(processed_text, voice=voice):
            # Unpack the result - same as in speak_monologue
            gs, ps, audio = result

            # Convert to numpy if it's a tensor
            if hasattr(audio, "cpu"):
                audio = audio.cpu().numpy()

            # Save to file
            sf.write(out_path, audio, tts_manager.sample_rate)
            return True

        # If we get here, no audio was generated
        print("No audio generated by TTS pipeline")
        return False

    except Exception as e:
        print(f"Error synthesizing text: {e}")
        return False


def test_tts_dialogue():
    """Generate a two-person Chinese dialogue (male/female), save as dialogue.wav"""
    import shutil
    from pathlib import Path

    from pydub import AudioSegment

    config = load_config("config/default.yaml")
    if "audio" not in config:
        config["audio"] = {}
    config["audio"]["enabled"] = True
    audio_config = config.get("audio", {})
    tts_manager = TTSManager(audio_config)
    temp_dir = Path("temp_audio")
    temp_dir.mkdir(exist_ok=True)
    dialogue = [
        ("male", "你好，请问你今天有空吗？"),
        ("female", "你好，有什么事吗？"),
        ("male", "我想邀请你一起去喝咖啡。"),
        ("female", "好啊，几点见面？"),
        ("male", "下午三点可以吗？"),
        ("female", "没问题，三点见！"),
    ]
    # Map gender to voice_id (adjust if your TTSManager supports these IDs)
    voice_map = {
        "male": audio_config.get("voice_id_male", "zm_010"),
        "female": audio_config.get("voice_id_female", "zf_001"),
    }
    audio_segments = []
    for idx, (gender, text) in enumerate(dialogue):
        out_path = temp_dir / f"line_{idx}.wav"
        logger.info(f"Synthesizing ({gender}) '{text}' -> {out_path}")
        synthesize_to_wav(tts_manager, text, str(out_path), voice_map[gender])
        audio_segments.append(AudioSegment.from_wav(str(out_path)))
    # Concatenate all segments
    final_audio = sum(audio_segments)
    final_audio.export("dialogue.wav", format="wav")
    logger.info("✅ Dialogue saved to dialogue.wav")
    shutil.rmtree(temp_dir)


def test_tts_english_dialogue():
    """Generate a two-person English dialogue (male/female), save as english_dialogue.wav"""
    import shutil
    from pathlib import Path

    from pydub import AudioSegment

    # Initialize TTS manager
    config = load_config("config/default.yaml")
    if "audio" not in config:
        config["audio"] = {}
    config["audio"]["enabled"] = True
    audio_config = config.get("audio", {})
    tts_manager = TTSManager(audio_config)

    # Create temp directory if it doesn't exist
    temp_dir = Path("temp_audio")
    temp_dir.mkdir(exist_ok=True)

    # Define dialogue lines with alternating speakers
    dialogue = [
        ("male", "Hello, do you have time today?"),
        ("female", "Hi there, what's up?"),
        ("male", "I'd like to invite you for coffee."),
        ("female", "Sure, what time works for you?"),
        ("male", "How about 3 PM?"),
        ("female", "Perfect, see you at 3!"),
    ]

    # Map gender to voice_id
    voice_map = {
        "male": audio_config.get("voice_id_male", "zm_010"),
        "female": audio_config.get("voice_id_female", "zf_001"),
    }

    # Generate audio for each line
    audio_segments = []
    for idx, (gender, text) in enumerate(dialogue):
        out_path = temp_dir / f"en_line_{idx}.wav"
        logger.info(f"Synthesizing ({gender}) '{text}' -> {out_path}")
        synthesize_to_wav(tts_manager, text, str(out_path), voice_map[gender])
        audio_segments.append(AudioSegment.from_wav(str(out_path)))

    # Concatenate all segments
    final_audio = sum(audio_segments)
    final_audio.export("english_dialogue.wav", format="wav")
    logger.info("✅ English dialogue saved to english_dialogue.wav")

    # Clean up temp files
    for idx in range(len(dialogue)):
        temp_file = temp_dir / f"en_line_{idx}.wav"
        if temp_file.exists():
            temp_file.unlink()


def play_audio_numpy_free(audio_tensor, sample_rate=24000):
    """
    Play audio without relying on NumPy conversion.
    This function provides multiple fallback methods for audio playback.

    Args:
        audio_tensor: PyTorch tensor containing audio data
        sample_rate: Sample rate of the audio (default: 24000)

    Returns:
        bool: True if playback was successful, False otherwise
    """
    import os
    import platform
    import subprocess
    import time
    from pathlib import Path

    import torch

    # Create temp directory if it doesn't exist
    temp_dir = Path("temp_audio")
    temp_dir.mkdir(exist_ok=True)

    # Generate a unique filename based on timestamp
    timestamp = int(time.time() * 1000)
    temp_file = temp_dir / f"temp_audio_{timestamp}.wav"

    # Make sure audio is on CPU and detached from computation graph
    if torch.is_tensor(audio_tensor):
        audio_cpu = audio_tensor.detach().cpu()

        # Reshape tensor if needed (audio libraries expect [channels, samples])
        if len(audio_cpu.shape) == 1:
            # Convert 1D tensor to 2D (1 channel)
            audio_cpu = audio_cpu.unsqueeze(0)  # Add channel dimension
            logger.info(
                f"Reshaped tensor from 1D to 2D with shape: {audio_cpu.shape}")
    else:
        logger.error(f"Unsupported audio type: {type(audio_tensor)}")
        return False

    # Method 1: Try torchaudio (may fail with NumPy 2.x)
    try:
        import torchaudio

        torchaudio.save(str(temp_file), audio_cpu, sample_rate)
        logger.info(f"Saved audio using torchaudio to {temp_file}")
        success = True
    except Exception as e:
        logger.warning(f"Failed to save audio using torchaudio: {e}")
        success = False

    # Method 2: Try scipy.io.wavfile (may have better NumPy 2.x compatibility)
    if not success:
        try:
            import scipy.io.wavfile

            # Convert to numpy carefully
            try:
                # Scale to int16 range
                audio_np = (
                    audio_cpu.squeeze(0).numpy() *
                    32767).astype("int16")
                scipy.io.wavfile.write(str(temp_file), sample_rate, audio_np)
                logger.info(
                    f"Saved audio using scipy.io.wavfile to {temp_file}")
                success = True
            except Exception as numpy_err:
                logger.warning(f"NumPy conversion failed: {numpy_err}")
                # Try direct tensor operations
                audio_int = (audio_cpu.squeeze(0) * 32767).to(torch.int16)
                with open(str(temp_file), "wb") as f:
                    # Create minimal WAV header manually
                    # RIFF header
                    f.write(b"RIFF")
                    f.write((36 + len(audio_int) * 2).to_bytes(4, "little"))
                    f.write(b"WAVE")
                    # fmt chunk
                    f.write(b"fmt ")
                    f.write((16).to_bytes(4, "little"))
                    f.write((1).to_bytes(2, "little"))  # PCM format
                    f.write((1).to_bytes(2, "little"))  # Mono
                    f.write(sample_rate.to_bytes(4, "little"))
                    f.write((sample_rate * 2).to_bytes(4, "little"))
                    f.write((2).to_bytes(2, "little"))
                    f.write((16).to_bytes(2, "little"))
                    # data chunk
                    f.write(b"data")
                    f.write((len(audio_int) * 2).to_bytes(4, "little"))
                    # Write the actual audio data
                    f.write(audio_int.numpy().tobytes())
                logger.info(
                    f"Saved audio using manual WAV writing to {temp_file}")
                success = True
        except Exception as e:
            logger.warning(f"Failed to save audio using scipy: {e}")
            success = False

    # If we managed to save the file, play it using system commands
    if success and temp_file.exists():
        try:
            system = platform.system().lower()
            if system == "darwin":  # macOS
                subprocess.run(["afplay", str(temp_file)], check=True)
            elif system == "linux":
                subprocess.run(["aplay", str(temp_file)], check=True)
            elif system == "windows":
                subprocess.run(["start", str(temp_file)],
                               shell=True, check=True)
            else:
                logger.error(f"Unsupported platform: {system}")
                return False
            logger.info("Audio playback completed successfully")
            return True
        except Exception as e:
            logger.error(f"Error playing audio file: {e}")
            return False
    else:
        logger.error("Failed to save audio file for playback")
        return False


def test_file_based_fallback():
    """Test the file-based fallback method for audio playback"""
    from pathlib import Path

    import torch

    # Initialize TTS manager
    config = load_config("config/default.yaml")
    if "audio" not in config:
        config["audio"] = {}
    config["audio"]["enabled"] = True
    tts_manager = TTSManager(config)

    # Create temp directory if it doesn't exist
    temp_dir = Path("temp_audio")
    temp_dir.mkdir(exist_ok=True)

    # Test text
    test_text = "这是一个测试，用于检查文本转语音功能。"
    logger.info(f"Testing file-based fallback with text: '{test_text}'")

    # Process the text using the pipeline to get audio tensor
    audio_tensor = None
    for result in tts_manager.zh_pipeline(
            test_text, voice=tts_manager.voice_id):
        gs, ps, audio = result
        audio_tensor = audio
        break

    if audio_tensor is None:
        logger.error("Failed to generate audio tensor")
        return

    # Print tensor shape and type information for debugging
    logger.info(f"Audio tensor type: {type(audio_tensor)}")
    logger.info(f"Audio tensor shape: {audio_tensor.shape}")
    logger.info(f"Audio tensor dtype: {audio_tensor.dtype}")

    # Test our new NumPy-free audio playback function
    success = play_audio_numpy_free(audio_tensor, tts_manager.sample_rate)
    if success:
        logger.info("✅ NumPy-free audio playback worked successfully")
    else:
        logger.error("❌ NumPy-free audio playback failed")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Test TTS functionality")
    parser.add_argument(
        "--dialogue", action="store_true", help="Test dialogue generation"
    )
    parser.add_argument(
        "--english",
        action="store_true",
        help="Test English dialogue generation")
    parser.add_argument(
        "--fallback", action="store_true", help="Test file-based fallback"
    )
    args = parser.parse_args()

    if args.dialogue:
        test_tts_dialogue()
    elif args.english:
        test_tts_english_dialogue()
    elif args.fallback:
        test_file_based_fallback()
    else:
        test_tts_initialization()
